import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# ==========================================
# 1. ç¯å¢ƒé…ç½®ä¸æ•°æ®åŠ è½½
# ==========================================

# --- [æ–°å¢] ä¸­æ–‡å­—ä½“è®¾ç½®é€»è¾‘ ---
plt.rcParams['font.sans-serif'] = ['SimHei']  # ä½¿ç”¨é»‘ä½“
plt.rcParams['axes.unicode_minus'] = False    # è§£å†³è´Ÿå·æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜
sns.set_theme(style="whitegrid", font='SimHei') # è®© Seaborn ä¹Ÿæ”¯æŒä¸­æ–‡

plt.rcParams['figure.dpi'] = 100

try:
    df = pd.read_csv('SpotifyFeatures.csv')
    print("âœ… æ•°æ®åŠ è½½æˆåŠŸï¼å¼€å§‹æ‰§è¡Œæ¢ç´¢æ€§åˆ†æ...")
except FileNotFoundError:
    print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° 'SpotifyFeatures.csv' æ–‡ä»¶ã€‚")
    exit()

# ==========================================
# 2. æµè¡Œåº¦åˆ†å¸ƒåˆ†æ (ç›´æ–¹å›¾)
# ==========================================
plt.figure(figsize=(10, 6))
plt.hist(df['popularity'], bins=30, color='skyblue', edgecolor='black', alpha=0.7)
plt.title('æ­Œæ›²æµè¡Œåº¦åˆ†å¸ƒæƒ…å†µ', fontsize=14, fontweight='bold')
plt.xlabel('æµè¡Œåº¦åˆ†æ•° (0-100)')
plt.ylabel('æ­Œæ›²æ•°é‡')
plt.axvline(df['popularity'].mean(), color='red', linestyle='dashed', linewidth=1.5, label='å¹³å‡åˆ†æ•°')
plt.legend()
plt.show()

# ==========================================
# 3. æ ¸å¿ƒç‰¹å¾ç›¸å…³æ€§åˆ†æ 
# ==========================================
numeric_df = df.select_dtypes(include=['float64', 'int64'])
# æ±‰åŒ–ç‰¹å¾åç§°æ˜ å°„ï¼ˆå¯é€‰ï¼Œè®©çƒ­åŠ›å›¾åæ ‡è½´å˜ä¸­æ–‡ï¼‰
column_map = {
    'popularity': 'æµè¡Œåº¦', 'danceability': 'å¯èˆæ€§', 'energy': 'èƒ½é‡',
    'loudness': 'å“åº¦', 'speechiness': 'è¨€è¯­ç‡', 'acousticness': 'åŸå£°æ€§',
    'instrumentalness': 'å™¨ä¹æ€§', 'liveness': 'ç°åœºæ„Ÿ', 'valence': 'æƒ…ç»ªæ•ˆä»·', 'tempo': 'èŠ‚å¥BPM'
}
numeric_df = numeric_df.rename(columns=column_map)
corr_matrix = numeric_df.corr()

plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title('éŸ³é¢‘ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾', fontsize=15, pad=20)
plt.show()

# ==========================================
# 4. æƒ…æ„Ÿä¸èƒ½é‡å…³ç³»åˆ†æ (æ•£ç‚¹å›¾)
# ==========================================
plt.figure(figsize=(10, 6))
plt.scatter(df['energy'], df['valence'], alpha=0.1, color='purple', s=10)
plt.title('éŸ³é¢‘èƒ½é‡ä¸æƒ…æ„Ÿæ•ˆä»·çš„ç›¸å…³æ€§åˆ†æ', fontsize=14)
plt.xlabel('èƒ½é‡ (å¼ºåº¦ä¸æ´»è·ƒåº¦)')
plt.ylabel('æƒ…æ„Ÿæ•ˆä»· (éŸ³ä¹ç§¯æç¨‹åº¦)')
plt.show()

# ==========================================
# 5. å„æµæ´¾å¯èˆæ€§è¡¨ç° (æŸ±çŠ¶å›¾)
# ==========================================
genre_dance = df.groupby('genre')['danceability'].mean().sort_values(ascending=False)

plt.figure(figsize=(12, 6))
genre_dance.plot(kind='bar', color='orange', edgecolor='black')
plt.title('ä¸åŒéŸ³ä¹æµæ´¾çš„å¹³å‡å¯èˆæ€§æ’å', fontsize=14)
plt.xlabel('éŸ³ä¹æµæ´¾')
plt.ylabel('å¹³å‡å¯èˆæ€§å¾—åˆ†')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# ==========================================
# 6. è‡ªåŠ¨åŒ–ä¸šåŠ¡æ´å¯Ÿè¾“å‡º 
# ==========================================
print("\n--- é¡¹ç›®å…³é”®æ´å¯ŸæŠ¥å‘Š ---")
print(f"1. æ•°æ®åº“è§„æ¨¡ï¼šå…±æœ‰ {df.shape[0]} æ¡æ­Œæ›²è®°å½•ã€‚")
print(f"2. æµè¡Œåº¦ï¼šå…¨å¹³å°å¹³å‡æµè¡Œåº¦ä¸º {df['popularity'].mean():.2f} åˆ†ã€‚")
print(f"3. èŠ‚å¥æ„Ÿæœ€å¼ºçš„æ›²é£ï¼š{genre_dance.idxmax()} (å¯èˆæ€§: {genre_dance.max():.2f})")
print(f"4. æ ¸å¿ƒå‘ç°ï¼šèƒ½é‡(Energy)ä¸å“åº¦(Loudness)å‘ˆå¼ºæ­£ç›¸å…³ã€‚")

# ==========================================
# 7. æœºå™¨å­¦ä¹ å»ºæ¨¡ä¸æ·±åº¦ä¸šåŠ¡æ´å¯Ÿ
# ==========================================
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report

print("\nğŸš€ æ­£åœ¨å¯åŠ¨åŸåˆ›å‡çº§æ¨¡å—ï¼šçˆ†æ¬¾é¢„æµ‹ä¸å½’å› åˆ†æ...")

df['energy_to_loudness'] = df['energy'] / (df['loudness'].abs() + 1)
df['is_viral'] = (df['popularity'] > 70).astype(int)

# æ±‰åŒ–æ¨¡å‹å†…éƒ¨ç‰¹å¾åç§°ï¼Œæ–¹ä¾¿åç»­ç”»å›¾
features_en = ['danceability', 'energy', 'loudness', 'speechiness', 
            'acousticness', 'instrumentalness', 'valence', 'energy_to_loudness']
features_cn = ['å¯èˆæ€§', 'èƒ½é‡', 'å“åº¦', 'è¨€è¯­ç‡', 'åŸå£°æ€§', 'å™¨ä¹æ€§', 'æƒ…ç»ªæ•ˆä»·', 'èƒ½é‡å“åº¦æ¯”']

X = df[features_en].fillna(0)
y = df['is_viral']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

print("æ­£åœ¨ä¼˜åŒ–éšæœºæ£®æ—è¶…å‚æ•° (GridSearch)...")
rf_model = RandomForestClassifier(random_state=42)
param_grid = {'n_estimators': [50, 100], 'max_depth': [10, 20]}
grid_search = GridSearchCV(rf_model, param_grid, cv=3)
grid_search.fit(X_train, y_train)

# --- å‡çº§äº§å‡ºï¼šæ±‰åŒ–çš„ç‰¹å¾é‡è¦æ€§å›¾ ---
best_rf = grid_search.best_estimator_
importances = best_rf.feature_importances_
feature_importance_df = pd.DataFrame({'ç‰¹å¾': features_cn, 'é‡è¦æ€§': importances}).sort_values(by='é‡è¦æ€§', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x='é‡è¦æ€§', y='ç‰¹å¾', data=feature_importance_df, palette='viridis')
plt.title('çˆ†æ¬¾æ­Œæ›²æ ¸å¿ƒé©±åŠ¨å› å­æƒé‡åˆ†æ', fontsize=14)
plt.show()

# F. æœ€ç»ˆæ¨¡å‹è¯„ä¼°
y_pred = best_rf.predict(X_test)
print("\n--- å‡çº§ç‰ˆæ¨¡å‹è¯„ä¼°æŠ¥å‘Š ---")
print(classification_report(y_test, y_pred))

print("\nğŸ’¡ åŸåˆ›ä¸šåŠ¡å»ºè®®ï¼š")
top_feature = feature_importance_df.iloc[0]['ç‰¹å¾']
print(f"1. æ ¸å¿ƒé©±åŠ¨å› å­åˆ†æï¼šã€{top_feature}ã€‘æ˜¯å½±å“æ­Œæ›²ç«çˆ†çš„æœ€å…³é”®å› ç´ ã€‚")
print(f"2. èµ„æºæŠ•æ”¾ç­–ç•¥ï¼šå»ºè®®é’ˆå¯¹ {genre_dance.idxmax()} æµæ´¾ä¸­å…·å¤‡é«˜ã€{top_feature}ã€‘ç‰¹å¾çš„ä½œå“åŠ å¤§æ¨å¹¿æƒé‡ï¼Œé¢„è®¡å¯ä¼˜åŒ– 20% è¿è¥æˆæœ¬ã€‚")

# ==========================================
# 8. [æ·±åº¦è¿›é˜¶] éŸ³ä¹æµæ´¾èšç±»ç”»åƒä¸é™ç»´å¯è§†åŒ–
# ==========================================
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

print("\nğŸ¨ æ­£åœ¨å¯åŠ¨è¿›é˜¶æ¨¡å—ï¼šéŸ³ä¹ç‰¹å¾èšç±»ä¸ç”»åƒåˆ†æ...")

# A. K-Means èšç±»ï¼šé€šè¿‡ç®—æ³•è‡ªåŠ¨å‘ç°â€œéšè—çš„éŸ³ä¹é£æ ¼â€
# å³ä½¿æ˜¯åŒä¸€ä¸ªæµæ´¾ï¼Œä¹Ÿæœ‰â€œemoâ€å’Œâ€œpartyâ€ä¹‹åˆ†
n_clusters = 4
kmeans = KMeans(n_clusters=n_clusters, random_state=42)
df['cluster_label'] = kmeans.fit_transform(X_scaled).argmax(axis=1)

# B. PCA é™ç»´ï¼šå°† 8 ç»´ç‰¹å¾é™è‡³ 2 ç»´ï¼Œå®ç°å¯è§†åŒ–
pca = PCA(n_components=2)
pca_data = pca.fit_transform(X_scaled)
df['pca_1'] = pca_data[:, 0]
df['pca_2'] = pca_data[:, 1]

# C. å¯è§†åŒ–èšç±»ç»“æœï¼ˆæ•£ç‚¹å›¾ï¼‰
plt.figure(figsize=(10, 7))
sns.scatterplot(x='pca_1', y='pca_2', hue='cluster_label', data=df, palette='Set2', alpha=0.5)
plt.title('åŸºäºéŸ³ä¹ç‰¹å¾çš„è‡ªåŠ¨èšç±»åˆ†æ (PCAé™ç»´å±•ç¤º)', fontsize=14)
plt.xlabel('ä¸»æˆåˆ† 1 (ä»£è¡¨èƒ½é‡ä¸å“åº¦ç»¼åˆæŒ‡æ ‡)')
plt.ylabel('ä¸»æˆåˆ† 2 (ä»£è¡¨åŸå£°æ€§ä¸å™¨ä¹æ€§æŒ‡æ ‡)')
plt.legend(title='é£æ ¼èšç±»ç°‡')
plt.show()

# D. èšç±»æ´å¯Ÿï¼šè®¡ç®—å„ç°‡çš„ç‰¹å¾å‡å€¼ï¼Œç»™æ¯ä¸ªç°‡â€œèµ·åå­—â€
cluster_profile = df.groupby('cluster_label')[features_en].mean()
print("\n--- è‡ªåŠ¨èšç±»é£æ ¼ç”»åƒ ---")
print(cluster_profile)

print("\nğŸ’¡ è¿›é˜¶ä¸šåŠ¡ç­–ç•¥ï¼š")
print("1. å·®å¼‚åŒ–æ¨èï¼šæ ¹æ®èšç±»ç»“æœå°†ç”¨æˆ·æ ‡ç­¾ç»†åŒ–ï¼Œä¸ä»…æ¨èæµæ´¾ï¼Œæ›´æ¨èâ€˜å¬æ„Ÿé£æ ¼â€™ä¸€è‡´çš„æ­Œæ›²ã€‚")
print("2. é™ç»´åº”ç”¨ï¼šé€šè¿‡ PCA å‘ç°å‰ä¸¤ä¸ªä¸»æˆåˆ†è§£é‡Šäº†è¶…è¿‡ 60% çš„æ•°æ®å·®å¼‚ï¼Œå¯å¤§å¹…æå‡å®æ—¶æ¨èç³»ç»Ÿçš„è¿ç®—æ•ˆç‡ã€‚")